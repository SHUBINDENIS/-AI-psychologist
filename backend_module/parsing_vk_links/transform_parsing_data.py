from typing import List, Any
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, MinMaxScaler


def data_preprocessing(users: pd.DataFrame, wall: pd.DataFrame) -> np.ndarray:
    print("üîß –ó–∞–ø—É—â–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è data_preprocessing")

    # -------------------
    # 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    # -------------------
    wall = wall.copy()
    wall['attachments'] = wall['attachments'].fillna('repost')
    wall['text_length'] = wall['text'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)

    users['status_len'] = users['status'].apply(lambda x: len(x) if isinstance(x, str) else 0)

    # -------------------
    # 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    # -------------------
    print("üìé –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ users –∏ wall...")
    df = users.merge(wall, left_on='screen_name', right_on='user_id', how='left')

    # -------------------
    # 3. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # -------------------
    print("üî§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    le = LabelEncoder()
    df['relation'] = le.fit_transform(df['relation'].fillna('–Ω–µ —É–∫–∞–∑–∞–Ω–æ'))
    df['sentiment'] = le.fit_transform(df['sentiment'].fillna('–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è'))

    # -------------------
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # -------------------
    print("üßÆ –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

    df.rename(columns={'user_id_x': 'user_id'}, inplace=True)

    sentiment_counts = df.groupby('user_id')['sentiment'].value_counts().unstack(fill_value=0)
    sentiment_counts = sentiment_counts.reindex(columns=[-1, 0, 1], fill_value=0)
    sentiment_counts.columns = ['neg_sum', 'neutral_sum', 'pos_sum']

    prob_stats = df.groupby('user_id')['custom_probability'].agg(
        mean_custom_prob='mean',
        median_custom_prob='median',
        std_custom_prob='std'
    ).reset_index()

    df = df.merge(sentiment_counts, on='user_id', how='left')
    df = df.merge(prob_stats, on='user_id', how='left')

    df['mean_text_length'] = df.groupby('user_id')['text_length'].transform('mean')
    df.drop(columns='text_length', inplace=True)

    # -------------------
    # 5. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–∞
    # -------------------
    df['sex'] = le.fit_transform(df['sex'])

    # -------------------
    # 6. –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    # -------------------
    print("üßπ –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è...")

    drop_cols = [
        'photo_max_orig', 'first_name', 'last_name', 'bdate', 'country', 'city',
        'home_town', 'interests', 'books', 'tv', 'quotes', 'games', 'movies', 'activities',
        'music', 'site', 'screen_name', 'occupation_type', 'occupation_name', 'religion',
        'inspired_by', 'date', 'type', 'mobile_phone ', 'home_phone  ', 'photos',
        'notes', 'gifts', 'groups', 'followers', 'university', 'political',
        'people_main', 'life_main', 'smoking', 'alcohol', 'user_id_y', 'attachments',
        'text', 'sentiment', 'custom_probability', 'status', 'user_id'
    ]
    df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True, errors='ignore')

    binarize_cols = [
        'has_photo', 'has_mobile', 'can_see_all_posts', 'can_see_audio',
        'can_write_private_message', 'can_send_friend_request', 'albums',
        'videos', 'friends', 'pages', 'subscriptions', 'can_access_closed',
        'mean_text_length', 'neg_sum', 'neutral_sum', 'pos_sum'
    ]
    df[binarize_cols] = df[binarize_cols].fillna(0).replace('', np.nan)
    df[binarize_cols] = df[binarize_cols].fillna(0).round().astype(int)

    fill_mean_cols = ['mean_custom_prob', 'median_custom_prob', 'std_custom_prob']
    for col in fill_mean_cols:
        df[col] = df[col].fillna(df[col].mean())

    df.drop(columns=['can_post', 'can_be_invited_group', 'audios', 'is_closed'], inplace=True, errors='ignore')
    df = df.drop_duplicates().fillna(df.mean(numeric_only=True))

    # -------------------
    # 7. –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    # -------------------

    required_columns = [
        'sex', 'relation', 'has_photo', 'has_mobile', 'can_see_all_posts',
        'can_see_audio', 'can_write_private_message', 'can_send_friend_request',
        'albums', 'videos', 'friends', 'pages', 'subscriptions',
        'can_access_closed', 'status_len',
        'neg_sum', 'neutral_sum', 'pos_sum', 'mean_custom_prob',
        'median_custom_prob', 'std_custom_prob', 'mean_text_length'
    ]

    # –ü—Ä–æ–≤–µ—Ä–∏–º, –≤—Å–µ –ª–∏ –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å—Ç—å
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –±—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –Ω—É–ª—è–º–∏: {missing_cols}")
        for col in missing_cols:
            df[col] = 0  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º 0

    # –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —É–±–µ–¥–∏–º—Å—è –≤ –ø–æ—Ä—è–¥–∫–µ
    df = df[required_columns]

    # –ó–∞–ø–æ–ª–Ω–∏–º NaN –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    df = df.fillna(0)

#     # -------------------
#     # 8. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
#     # -------------------
#     scaler = MinMaxScaler()
#     print("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è data_preprocessing")
#     return scaler.fit_transform(df)
    return df
